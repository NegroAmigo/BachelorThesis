{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NegroAmigo/BachelorThesis/blob/main/bachelors_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.2.103 -q\n",
        "!pip install roboflow\n",
        "!pip install -U ultralytics -q\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "7T2f-jhSLN_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CaevRP3a8KP",
        "outputId": "16d5bfb0-280c-4ad9-afce-409295504752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "from ultralytics import settings\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "rf = Roboflow(api_key=\"vzRLQrA2LEpOdmEObpb1\")\n",
        "project = rf.workspace(\"bachelorsworkspace\").project(\"3d-fdm-failures\")\n",
        "version = project.version(7)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "settings.update({\"wandb\": True})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIb4e_qBscw7"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/drive/MyDrive/Default_Train_pr/run_2/weights/best.pt')\n",
        "\n",
        "results = model('/content/3d-fdm-failures-6/valid/images/4-20-3-_jpg.rf.a03e4668ee3511f4387652e3baf20a3e.jpg', save=True, conf = 0.35)\n",
        "\n",
        "for r in results:\n",
        "    print(r.boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDxTB18sk8c"
      },
      "source": [
        "# **Drawing Predicted box with IoU**\n",
        "\n",
        "Scripts to draw boxes on original image with IoU and IoM and prediction class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slKfO34kuLwX"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(image, boxes, classes, color=(0, 255, 0), label_map=None, is_predicted=None, confidences=None):\n",
        "    img_copy = image.copy()\n",
        "    h, w = img_copy.shape[:2]\n",
        "    for i, (box, class_id) in enumerate(zip(boxes, classes)):\n",
        "        x_center, y_center, width, height = box\n",
        "        print(f\"Class: {class_id} x_center: {x_center} y_center: {y_center} width: {width} height: {height} \" )\n",
        "        x_min = int((x_center - width / 2) * w)\n",
        "        y_min = int((y_center - height / 2) * h)\n",
        "        x_max = int((x_center + width / 2) * w)\n",
        "        y_max = int((y_center + height / 2) * h)\n",
        "\n",
        "        print(f\"Mins: {x_min} {y_min} Max: {x_max} {y_max}\")\n",
        "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), color, 2)\n",
        "\n",
        "        if is_predicted:\n",
        "            confidence = confidences[i] if confidences is not None else 0.0\n",
        "            label = f\"{label_map[int(class_id)]} {confidence:.2f}\" if label_map else f\"Class {int(class_id)} {confidence:.2f}\"\n",
        "        else:\n",
        "            label = label_map[int(class_id)] if label_map else f\"Class {int(class_id)}\"\n",
        "        (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        if y_min - text_height - baseline < 0:\n",
        "            label_y_min = y_max + text_height + baseline\n",
        "            cv2.rectangle(img_copy, (x_min, y_max + baseline ), (x_min + text_width, y_max + text_height + baseline), (0, 0, 0), thickness=cv2.FILLED)\n",
        "            cv2.putText(img_copy, label, (x_min, y_max + text_height ), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "        else:\n",
        "            cv2.rectangle(img_copy, (x_min, y_min - text_height - baseline - 10), (x_min + text_width, y_min), (0, 0, 0), thickness=cv2.FILLED)\n",
        "            cv2.putText(img_copy, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    return img_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjQatP0q6Y92"
      },
      "outputs": [],
      "source": [
        "def yolo_to_coords(box, img_width, img_height):\n",
        "        x_center, y_center, width, height = box\n",
        "        width_half = (width * img_width) / 2\n",
        "        height_half = (height * img_height) / 2\n",
        "        x_min = (x_center * img_width) - width_half\n",
        "        y_min = (y_center * img_height) - height_half\n",
        "        x_max = (x_center * img_width) + width_half\n",
        "        y_max = (y_center * img_height) + height_half\n",
        "        return np.array([x_min, y_min, x_max, y_max])\n",
        "\n",
        "def calculate_iou(boxA, boxB, img_width, img_height):\n",
        "    # convert boxes from yolo to corner coord\n",
        "    boxA_corners = yolo_to_coords(boxA, img_width, img_height)\n",
        "    boxB_corners = yolo_to_coords(boxB, img_width, img_height)\n",
        "\n",
        "    xA = np.maximum(boxA_corners[0], boxB_corners[0])\n",
        "    yA = np.maximum(boxA_corners[1], boxB_corners[1])\n",
        "    xB = np.minimum(boxA_corners[2], boxB_corners[2])\n",
        "    yB = np.minimum(boxA_corners[3], boxB_corners[3])\n",
        "\n",
        "    # compute intersection of rectangles\n",
        "    interArea = np.maximum(0, xB - xA) * np.maximum(0, yB - yA)\n",
        "\n",
        "    # compute area of prediction and ground truth boxes\n",
        "    boxAArea = (boxA_corners[2] - boxA_corners[0]) * (boxA_corners[3] - boxA_corners[1])\n",
        "    boxBArea = (boxB_corners[2] - boxB_corners[0]) * (boxB_corners[3] - boxB_corners[1])\n",
        "\n",
        "    # compute IoU\n",
        "    iou = interArea / (boxAArea + boxBArea - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "def calculate_iom(boxA, boxB, img_width, img_height):\n",
        "    # convert boxes from yolo to corner coord\n",
        "    boxA_corners = yolo_to_coords(boxA, img_width, img_height)\n",
        "    boxB_corners = yolo_to_coords(boxB, img_width, img_height)\n",
        "\n",
        "    xA = np.maximum(boxA_corners[0], boxB_corners[0])\n",
        "    yA = np.maximum(boxA_corners[1], boxB_corners[1])\n",
        "    xB = np.minimum(boxA_corners[2], boxB_corners[2])\n",
        "    yB = np.minimum(boxA_corners[3], boxB_corners[3])\n",
        "\n",
        "    # compute intersection of rectangles\n",
        "    interArea = np.maximum(0, xB - xA) * np.maximum(0, yB - yA)\n",
        "\n",
        "    # compute area of prediction and ground truth boxes\n",
        "    boxAArea = (boxA_corners[2] - boxA_corners[0]) * (boxA_corners[3] - boxA_corners[1])\n",
        "    boxBArea = (boxB_corners[2] - boxB_corners[0]) * (boxB_corners[3] - boxB_corners[1])\n",
        "\n",
        "    # compute the intersection over minimum\n",
        "    minArea = min(boxAArea, boxBArea)\n",
        "    iom = interArea / minArea\n",
        "\n",
        "    return iom\n",
        "\n",
        "def compare_boxes(pred_boxes, gt_boxes, predicted_classes, ground_truth_classes, img_width, img_height, iou_threshold=0.5,iom_threshold=0.5):\n",
        "  matches = []\n",
        "  unmatched_pred = []\n",
        "  unmatched_gt = []\n",
        "\n",
        "  # create matrix of IoU between all predicted and ground truth boxes\n",
        "  iou_matrix = np.zeros((len(pred_boxes), len(gt_boxes)))\n",
        "  iom_matrix = np.zeros((len(pred_boxes), len(gt_boxes)))\n",
        "\n",
        "  for i, pred_box in enumerate(pred_boxes):\n",
        "      for j, gt_box in enumerate(gt_boxes):\n",
        "          iou_matrix[i, j] = calculate_iou(pred_box, gt_box, img_width, img_height)\n",
        "          iom_matrix[i, j] = calculate_iom(pred_box, gt_box, img_width, img_height)\n",
        "\n",
        "  # match predictions with ground truth boxes on highest IoU\n",
        "  pred_matched = np.zeros(len(pred_boxes), dtype=bool)\n",
        "  gt_matched = np.zeros(len(gt_boxes), dtype=bool)\n",
        "\n",
        "  # iterate over predictions to find best match in ground truth\n",
        "  for i in range(len(pred_boxes)):\n",
        "        best_gt_idx = np.argmax(iou_matrix[i])\n",
        "        best_iou = iou_matrix[i, best_gt_idx]\n",
        "        best_iom = iom_matrix[i, best_gt_idx]\n",
        "\n",
        "        # if both IoU and IoM exceed their thresholds and ground truth is not already matched\n",
        "        if best_iou >= iou_threshold and best_iom >= iom_threshold and not gt_matched[best_gt_idx]:\n",
        "            #matches.append((pred_boxes[i], gt_boxes[best_gt_idx], best_iou, best_iom))\n",
        "            matches.append((pred_boxes[i],gt_boxes[best_gt_idx], best_iou, best_iom, predicted_classes[i], ground_truth_classes[best_gt_idx]))\n",
        "            pred_matched[i] = True\n",
        "            gt_matched[best_gt_idx] = True\n",
        "\n",
        "    # collect unmatched predictions and ground truth boxes\n",
        "  unmatched_pred = [pred_boxes[i] for i in range(len(pred_boxes)) if not pred_matched[i]]\n",
        "  unmatched_gt = [gt_boxes[j] for j in range(len(gt_boxes)) if not gt_matched[j]]\n",
        "\n",
        "  return matches, unmatched_pred, unmatched_gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TqR0WIwskLi"
      },
      "outputs": [],
      "source": [
        "def place_label(img, label, x_min, boundary_y, color, align_above=False):\n",
        "        h, w = img.shape[:2]\n",
        "        (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)\n",
        "\n",
        "        # determine y-coordinate for label above or below boundary\n",
        "        if align_above:  # try to place label above the top boundary for predicted labels\n",
        "            label_y_min = boundary_y - baseline  # smaller gap by only subtracting baseline\n",
        "            if label_y_min < text_height:  # check if label is out of bounds above\n",
        "                label_y_min = boundary_y + text_height + baseline  # place below if above is out of bounds\n",
        "        else:  # place label slightly below bottom boundary for ground truth labels\n",
        "            label_y_min = boundary_y + baseline + 15 # smaller gap by using only baseline offset\n",
        "            if label_y_min + text_height > h:  # check if label is out of bounds below\n",
        "                label_y_min = boundary_y - text_height - baseline  # place above if below is out of bounds\n",
        "\n",
        "        # adjust x-coordinate if label goes beyond image width\n",
        "        label_x_min = max(0, min(x_min, w - text_width))\n",
        "\n",
        "        # draw filled rectangle background and text\n",
        "        cv2.rectangle(img, (label_x_min, label_y_min - text_height - baseline),\n",
        "                      (label_x_min + text_width, label_y_min), (0, 0, 0), thickness=cv2.FILLED)\n",
        "        cv2.putText(img, label, (label_x_min, label_y_min - 2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
        "\n",
        "\n",
        "\n",
        "def draw_boxes_with_iou(image_path, predicted_boxes, predicted_classes, ground_truth_boxes, ground_truth_classes, label_map, confidences=None):\n",
        "    img_copy = cv2.imread(image_path).copy()\n",
        "    h, w = img_copy.shape[:2]\n",
        "\n",
        "    # calculate IoU between predicted and ground-truth boxes\n",
        "    matches, unmatched_pred, unmatched_gt = compare_boxes(predicted_boxes, ground_truth_boxes,predicted_classes, ground_truth_classes, w, h)\n",
        "    cls_matches = []\n",
        "\n",
        "\n",
        "\n",
        "    # draw ground truth boxes (green)\n",
        "    for i, (gt_box, gt_class) in enumerate(zip(ground_truth_boxes, ground_truth_classes)):\n",
        "        x_center, y_center, width, height = gt_box\n",
        "        x_min = int((x_center - width / 2) * w)\n",
        "        y_min = int((y_center - height / 2) * h)\n",
        "        x_max = int((x_center + width / 2) * w)\n",
        "        y_max = int((y_center + height / 2) * h)\n",
        "\n",
        "        matched_id = None\n",
        "        for match_idx, (_, match_gt_box, _, _,_,_) in enumerate(matches):\n",
        "            if np.array_equal(match_gt_box, gt_box):\n",
        "                matched_id = match_idx\n",
        "                break\n",
        "\n",
        "        # matched ID to label if box is matched\n",
        "        if matched_id is not None:\n",
        "            label = f\"{matched_id}: {label_map[int(gt_class)]}\"\n",
        "        else:\n",
        "            label = f\"{label_map[int(gt_class)]}\"\n",
        "\n",
        "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "        #label = f\"{i}: {label_map[int(ground_truth_classes[i])]}\" if label_map else f\"Class {int(ground_truth_classes[i])}\"\n",
        "        # (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        # cv2.rectangle(img_copy, (x_min, y_max + text_height + baseline ), (x_min + text_width, y_max), (0, 0, 0), thickness=cv2.FILLED)\n",
        "        # cv2.putText(img_copy, label, (x_min, y_max + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "        place_label(img_copy, label, x_min, y_max, (0, 255, 0))\n",
        "\n",
        "    # draw predicted boxes (red) and IoU values\n",
        "    for i, ((pred_box, gt_box, iou, iom, _, _), conf) in enumerate(zip(matches, confidences)):\n",
        "        x_center, y_center, width, height = pred_box\n",
        "        x_min = int((x_center - width / 2) * w)\n",
        "        y_min = int((y_center - height / 2) * h)\n",
        "        x_max = int((x_center + width / 2) * w)\n",
        "        y_max = int((y_center + height / 2) * h)\n",
        "\n",
        "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)  # Blue for predicted\n",
        "\n",
        "        # Find corresponding class ID\n",
        "        for idx, (p_box, g_box, _, _, pred_cls, gt_cls) in enumerate(matches):\n",
        "            if np.array_equal(p_box, pred_box) and np.array_equal(g_box, gt_box):\n",
        "                class_id = predicted_classes[idx]\n",
        "                cls_matches.append((idx, int(pred_cls), gt_cls, os.path.basename(image_path)))\n",
        "                #cls_matches.append((idx, int(class_id), ground_truth_classes[idx]))\n",
        "                break\n",
        "\n",
        "        label = f\"{i}: {label_map[int(class_id)]} {conf:.2f} IoU: {iou:.2f}\" #IoM: {iom:.2f}\"\n",
        "        # (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        # cv2.rectangle(img_copy, (x_min, y_max + text_height + baseline), (x_min + text_width, y_max), (0, 0, 0), thickness=cv2.FILLED)\n",
        "        # cv2.putText(img_copy, label, (x_min, y_max +15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "        place_label(img_copy, label, x_min, y_min, (255, 255, 255), True)\n",
        "    return img_copy, cls_matches\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STATISTICAL SCRIPTS**\n",
        "\n",
        "Scripts which create .csv file for further analysis on which images model performs better/worse.\n",
        "\n",
        "`statistics_on_cls_matches` - creates csv. with models classification predictions\n",
        "\n",
        "`statistics_on_no_detection` - creates .csv with images where model did not detected any error\n"
      ],
      "metadata": {
        "id": "MXCgz-1ZX-HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics_on_cls_matches(images_folder, model_path):\n",
        "\n",
        "  model = YOLO(model_path)\n",
        "\n",
        "  for image_name in os.listdir(images_folder):\n",
        "    image_path = os.path.join(images_folder, image_name)\n",
        "    results = model(cv2.imread(image_path), conf=0.35, augment=False)\n",
        "\n",
        "    predicted_boxes = results[0].boxes.xywhn\n",
        "    predicted_classes = results[0].boxes.cls\n",
        "    predicted_confidence = results[0].boxes.conf\n",
        "\n",
        "\n",
        "    ground_truth_path = image_path.replace('.jpg', '.txt').replace('images', 'labels')\n",
        "    if not os.path.exists(ground_truth_path): continue\n",
        "    ground_truth_boxes = []\n",
        "    ground_truth_classes = []\n",
        "\n",
        "    with open(ground_truth_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "            ground_truth_boxes.append([x_center, y_center, width, height])\n",
        "            ground_truth_classes.append(int(class_id))\n",
        "\n",
        "    ground_truth_boxes = np.array(ground_truth_boxes)\n",
        "    predicted_boxes = predicted_boxes.cpu().numpy()\n",
        "\n",
        "    label_map = {0: \"Blobs\", 1: \"Cracks\", 2: \"Spaghetti\", 3: \"Stringging\", 4: \"Under Extrusion\"}\n",
        "\n",
        "    cls_matches_list =[]\n",
        "\n",
        "    predicted_img, cls_matches_list = draw_boxes_with_iou(image_path, predicted_boxes, predicted_classes, ground_truth_boxes, ground_truth_classes, label_map, confidences=results[0].boxes.conf)\n",
        "\n",
        "    output_csv_path = \"cls_matches.csv\"\n",
        "\n",
        "    file_exists = os.path.exists(output_csv_path) and os.path.getsize(output_csv_path) > 0\n",
        "\n",
        "    with open(output_csv_path, mode='a', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "\n",
        "        if not file_exists:\n",
        "              csv_writer.writerow([\"Match_ID\", \"Predicted_Class\", \"Ground_Truth_Class\", \"Image_Name\"])\n",
        "\n",
        "        csv_writer.writerows(cls_matches_list)\n"
      ],
      "metadata": {
        "id": "NrG2lroKW3jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistics_on_cls_matches('/content/3d-fdm-failures-7/valid/images', '/content/drive/MyDrive/BP_Experiments/Baseline_run/weights/best.pt')"
      ],
      "metadata": {
        "id": "QRRV7luYGnJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics_on_no_detection(images_folder, model_path):\n",
        "  model = YOLO(model_path)\n",
        "  total_instances = 0;\n",
        "  for image_name in os.listdir(images_folder):\n",
        "    image_path = os.path.join(images_folder, image_name)\n",
        "    results = model(cv2.imread(image_path), conf=0.35, augment=False)\n",
        "\n",
        "\n",
        "    predicted_boxes = results[0].boxes.xywhn\n",
        "    predicted_classes = results[0].boxes.cls\n",
        "    predicted_confidence = results[0].boxes.conf\n",
        "    ground_truth_path = image_path.replace('.jpg', '.txt').replace('images', 'labels')\n",
        "    if not os.path.exists(ground_truth_path): continue\n",
        "    ground_truth_boxes = []\n",
        "    ground_truth_classes = []\n",
        "\n",
        "    with open(ground_truth_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "            ground_truth_boxes.append([x_center, y_center, width, height])\n",
        "            ground_truth_classes.append(int(class_id))\n",
        "\n",
        "    total_instances += len(ground_truth_boxes)\n",
        "\n",
        "    label_map = {0: \"Blobs\", 1: \"Cracks\", 2: \"Spaghetti\", 3: \"Stringging\", 4: \"Under Extrusion\"}\n",
        "\n",
        "    if predicted_boxes.shape[0] == 0:\n",
        "\n",
        "      print(f\"No detection for image: {image_name}\")\n",
        "      output_csv_path = \"cls_no_detection.csv\"\n",
        "\n",
        "      class_names = [label_map[class_id] for class_id in ground_truth_classes]\n",
        "\n",
        "      file_exists = os.path.exists(output_csv_path) and os.path.getsize(output_csv_path) > 0\n",
        "\n",
        "      with open(output_csv_path, mode='a', newline='') as csv_file:\n",
        "          csv_writer = csv.writer(csv_file)\n",
        "\n",
        "          if not file_exists:\n",
        "                csv_writer.writerow([\"Ground_Truth_Classes\", \"Image_Name\"])\n",
        "\n",
        "          for class_name in class_names:\n",
        "            csv_writer.writerow([class_name, os.path.basename(image_path)])\n",
        "    print(total_instances)\n"
      ],
      "metadata": {
        "id": "84VdJVRCJRtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistics_on_no_detection('/content/3d-fdm-failures-6/valid/images', '/content/drive/MyDrive/NoAug_NoMosaic_CosLR_pr/run_2/weights/best.pt')"
      ],
      "metadata": {
        "id": "n8J-5xF9M4AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DIAGNOSTIC MATRIX SCRIPT**\n",
        "\n",
        "Script which creates matrices of models predictions. Each mosaic represents the model predictions on a picture from the validation split of a created dataset. The mosaic is divided into 4 parts, where the top left picture is an example of misclassification, the top right picture is low-confidence predictions, the bottom left picture is missed detections, and the bottom right picture is high-confidence predictions."
      ],
      "metadata": {
        "id": "FBsZddSrYr1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_diagnostic_mosaic(images_folder, weights_path, save_dir='diagnostics_output', output_name='diagnostic_mosaic.jpeg'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    model = YOLO(weights_path)\n",
        "    label_map = {0: \"Blobs\", 1: \"Cracks\", 2: \"Spaghetti\", 3: \"Stringging\", 4: \"Under Extrusion\"}\n",
        "\n",
        "    misclassified_imgs = []\n",
        "    low_conf_imgs = []\n",
        "    no_detection_imgs = []\n",
        "    high_conf_imgs = []\n",
        "\n",
        "    for image_name in os.listdir(images_folder):\n",
        "        if not image_name.endswith(('.jpg', '.png')):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(images_folder, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model(image, conf=0.15)\n",
        "        pred = results[0]\n",
        "\n",
        "        pred_boxes = pred.boxes.xywhn.cpu().numpy() if pred.boxes else np.array([])\n",
        "        pred_classes = pred.boxes.cls.cpu().numpy().astype(int) if pred.boxes else np.array([])\n",
        "        pred_conf = pred.boxes.conf.cpu().numpy() if pred.boxes else np.array([])\n",
        "\n",
        "        gt_path = image_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
        "        if not os.path.exists(gt_path):\n",
        "            continue\n",
        "\n",
        "        ground_truth_boxes = []\n",
        "        ground_truth_classes = []\n",
        "        with open(gt_path, 'r') as f:\n",
        "            for line in f:\n",
        "                cls_id, x, y, w, h = map(float, line.strip().split())\n",
        "                ground_truth_boxes.append([x, y, w, h])\n",
        "                ground_truth_classes.append(int(cls_id))\n",
        "\n",
        "        # no predictions but ground truth exists\n",
        "        if pred_boxes.shape[0] == 0 and len(ground_truth_boxes) > 0:\n",
        "            annotated_img, _ = draw_boxes_with_iou(image_path, pred_boxes, pred_classes,\n",
        "                                                   ground_truth_boxes, ground_truth_classes,\n",
        "                                                   label_map, confidences=[])\n",
        "            no_detection_imgs.append(annotated_img)\n",
        "            continue\n",
        "\n",
        "        if pred_boxes.shape[0] > 0 and len(ground_truth_boxes) > 0:\n",
        "            annotated_img, cls_matches = draw_boxes_with_iou(image_path, pred_boxes, pred_classes,\n",
        "                                                             ground_truth_boxes, ground_truth_classes,\n",
        "                                                             label_map, confidences=pred_conf)\n",
        "\n",
        "            for match_id, pred_cls, gt_cls, _ in cls_matches:\n",
        "                if pred_cls != gt_cls:\n",
        "                    misclassified_imgs.append(annotated_img)\n",
        "                    break\n",
        "                elif pred_cls == gt_cls and pred_conf[match_id] < 0.3:\n",
        "                    low_conf_imgs.append(annotated_img)\n",
        "                    break\n",
        "                elif pred_cls == gt_cls and pred_conf[match_id] >= 0.7:\n",
        "                    high_conf_imgs.append(annotated_img)\n",
        "\n",
        "\n",
        "        # early break if we have at least one for each category\n",
        "        if (len(misclassified_imgs) > 0 and len(low_conf_imgs) > 0 and\n",
        "            len(no_detection_imgs) > 0 and len(high_conf_imgs) > 0):\n",
        "            break\n",
        "\n",
        "    # pick random images or fallback to white canvas\n",
        "    def pick_random_or_blank(lst):\n",
        "        if len(lst) > 0:\n",
        "            return random.choice(lst)\n",
        "        else:\n",
        "            return np.ones((384, 512, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    mosaic_images = [\n",
        "        pick_random_or_blank(misclassified_imgs),\n",
        "        pick_random_or_blank(low_conf_imgs),\n",
        "        pick_random_or_blank(no_detection_imgs),\n",
        "        pick_random_or_blank(high_conf_imgs)\n",
        "    ]\n",
        "\n",
        "    resized_images = [cv2.resize(img, (512, 384)) for img in mosaic_images]\n",
        "    top_row = np.hstack(resized_images[:2])\n",
        "    bottom_row = np.hstack(resized_images[2:])\n",
        "    mosaic = np.vstack([top_row, bottom_row])\n",
        "\n",
        "    output_path = os.path.join(save_dir, output_name)\n",
        "    cv2.imwrite(output_path, mosaic)\n",
        "    print(f\"Mosaic saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "g8SL9XTiEoSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_diagnostic_mosaic(\n",
        "    images_folder='/content/3d-fdm-failures-7/valid/images',\n",
        "    weights_path='/content/drive/MyDrive/BP_Experiments/Adamax_DropOut_02_yolo_s/weights/best.pt',\n",
        "    output_name='Adamax_DropOut_03_diagnostic_mosaic.jpeg'\n",
        ")"
      ],
      "metadata": {
        "id": "mbIC0W4ZEpZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runs create_diagnostic_mosaic for all models inside BP_Experiments\n",
        "def run_all_diagnostics(base_experiments_dir, images_folder, save_dir='diagnostics_output'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for experiment in os.listdir(base_experiments_dir):\n",
        "        experiment_path = os.path.join(base_experiments_dir, experiment)\n",
        "        model_path = os.path.join(experiment_path, 'weights', 'best.pt')\n",
        "\n",
        "        if not os.path.isfile(model_path):\n",
        "            print(f\"Skipping {experiment} – no best.pt found.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Running diagnostics for: {experiment}\")\n",
        "        create_diagnostic_mosaic(\n",
        "            images_folder=images_folder,\n",
        "            weights_path=model_path,\n",
        "            save_dir=save_dir,\n",
        "            output_name=f\"{experiment}_diagnostic_mosaic.jpeg\"\n",
        "        )\n",
        "\n",
        "run_all_diagnostics(\n",
        "  base_experiments_dir='/content/drive/MyDrive/BP_Experiments',\n",
        "  images_folder='/content/3d-fdm-failures-7/valid/images'\n",
        ")\n"
      ],
      "metadata": {
        "id": "aMbjquHzJqAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMPARISON SCRIPT**\n",
        "\n",
        "Simple script, which takes 2 versions of models, throws plot of their predictions on same image"
      ],
      "metadata": {
        "id": "SEgr0Oo7Z0Fy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj7lYSb8GTTt"
      },
      "outputs": [],
      "source": [
        "def load_ground_truth_boxes(image_path):\n",
        "    ground_truth_path = image_path.replace('.jpg', '.txt').replace('images', 'labels')\n",
        "    ground_truth_boxes = []\n",
        "    ground_truth_classes = []\n",
        "\n",
        "    with open(ground_truth_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "            ground_truth_boxes.append([x_center, y_center, width, height])\n",
        "            ground_truth_classes.append(int(class_id))\n",
        "\n",
        "    return np.array(ground_truth_boxes), ground_truth_classes\n",
        "\n",
        "def compare_models_on_image(model_path1, model_path2, image_path, conf_threshold=0.0):\n",
        "\n",
        "    model1 = YOLO(model_path1)\n",
        "    model2 = YOLO(model_path2)\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    ground_truth_boxes, ground_truth_classes = load_ground_truth_boxes(image_path)\n",
        "\n",
        "    label_map = {0: \"Blobs\", 1: \"Cracks\", 2: \"Spaghetti\", 3: \"Stringging\", 4: \"Under Extrusion\"}\n",
        "\n",
        "    results1 = model1(image, conf=conf_threshold)\n",
        "    results2 = model2(image, conf=conf_threshold)\n",
        "\n",
        "    predicted_boxes1 = results1[0].boxes.xywhn.cpu().numpy()\n",
        "    predicted_classes1 = results1[0].boxes.cls.cpu().numpy()\n",
        "    predicted_confidence1 = results1[0].boxes.conf.cpu().numpy()\n",
        "\n",
        "    predicted_boxes2 = results2[0].boxes.xywhn.cpu().numpy()\n",
        "    predicted_classes2 = results2[0].boxes.cls.cpu().numpy()\n",
        "    predicted_confidence2 = results2[0].boxes.conf.cpu().numpy()\n",
        "\n",
        "    image_with_boxes1 = draw_boxes_with_iou(\n",
        "        image, predicted_boxes1, predicted_classes1, ground_truth_boxes, ground_truth_classes, label_map, confidences=predicted_confidence1\n",
        "    )\n",
        "    image_with_boxes2 = draw_boxes_with_iou(\n",
        "        image, predicted_boxes2, predicted_classes2, ground_truth_boxes, ground_truth_classes, label_map, confidences=predicted_confidence2\n",
        "    )\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
        "    axs[0].imshow(cv2.cvtColor(image_with_boxes1, cv2.COLOR_BGR2RGB))\n",
        "    axs[0].set_title(\"Model 1 Predictions\")\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(cv2.cvtColor(image_with_boxes2, cv2.COLOR_BGR2RGB))\n",
        "    axs[1].set_title(\"Model 2 Predictions\")\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMn1lcnbHbMZ"
      },
      "outputs": [],
      "source": [
        "model1_path = '/content/drive/MyDrive/Default_Train_pr/run_2/weights/best.pt'\n",
        "model2_path = '/content/drive/MyDrive/NoAug_NoMosaic_CosLR_pr/300_epochs_run/weights/best.pt'\n",
        "image_path = '/content/3d-fdm-failures-6/valid/images/5-20-20-_jpg.rf.4b297853959ddedf6858816dc358ed22.jpg'\n",
        "compare_models_on_image(model1_path, model2_path, image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATION TABLE SCRIPT**\n",
        "\n",
        "Similar script to train script, but runs evaluation on each configuration"
      ],
      "metadata": {
        "id": "BLFHDy2bbI5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yaml_config(yaml_path):\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "\n",
        "def get_model_checkpoint(experiment_root):\n",
        "    model_path = os.path.join(experiment_root, \"weights\", \"best.pt\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model best.pt not found: {model_path}\")\n",
        "    return model_path\n",
        "\n",
        "\n",
        "def evaluate_yolo_model(model_path, data_path, save_dir=None):\n",
        "    model = YOLO(model_path)\n",
        "    results = model.val(data=data_path, save=True, save_dir=save_dir)\n",
        "    print(f\"Evaluation completed for {model_path} completed\")\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_all_evaluations(experiment_root_dir, config_dir, dataset_root=None):\n",
        "    for file in os.listdir(config_dir):\n",
        "        if file.endswith('.yaml'):\n",
        "            config_path = os.path.join(config_dir, file)\n",
        "            config = load_yaml_config(config_path)\n",
        "\n",
        "            name = config.get('name')\n",
        "            data_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "            experiment_dir = os.path.join(experiment_root_dir, name)\n",
        "            try:\n",
        "                model_path = get_model_checkpoint(experiment_dir)\n",
        "                print(f\"Evaluating {model_path} ...\")\n",
        "                evaluate_yolo_model(model_path, data_path, save_dir=os.path.join(experiment_dir, 'val_results'))\n",
        "            except Exception as e:\n",
        "                print(f\"Evaluation failed for {model_path}: {e}\")"
      ],
      "metadata": {
        "id": "fMM_cLwGaqjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANNOTATIONS CONVERSION**\n",
        "\n",
        "Script which converts existing segmentation annotations to bounding boxes"
      ],
      "metadata": {
        "id": "gr2FehxEbXuF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m-6ekFYMmSV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def convert_segmentation_to_yolo(input_folder, output_folder, image_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for label_file in os.listdir(input_folder):\n",
        "        if label_file.endswith(\".txt\"):\n",
        "\n",
        "            image_filename = os.path.splitext(label_file)[0] + '.jpg'\n",
        "            image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "            with Image.open(image_path) as img:\n",
        "                image_width, image_height = img.size\n",
        "\n",
        "            with open(os.path.join(input_folder, label_file), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            #print(f\"IMAGE WORKING ON: {image_filename} WIDTH: {image_width} HEIGHT: {image_height}\")\n",
        "\n",
        "            new_labels = []\n",
        "            for line in lines:\n",
        "                data = line.strip().split()\n",
        "                class_id = int(data[0])\n",
        "                coords = list(map(float, data[1:]))\n",
        "\n",
        "                x_coords = coords[0::2]\n",
        "                y_coords = coords[1::2]\n",
        "\n",
        "                x_min = min(x_coords)\n",
        "                x_max = max(x_coords)\n",
        "                y_min = min(y_coords)\n",
        "                y_max = max(y_coords)\n",
        "\n",
        "                #print(f\"X_MIN: {x_min} X_MAX: {x_max}\\nY_MIN: {y_min} Y_MAX: {y_max}\")\n",
        "\n",
        "                center_x = (x_min + ((x_max - x_min)/2))\n",
        "                center_y = (y_min + ((y_max - y_min)/2))\n",
        "                box_width = (x_max - x_min)\n",
        "                box_height = (y_max - y_min)\n",
        "\n",
        "                new_label = f\"{class_id} {center_x:.6f} {center_y:.6f} {box_width:.6f} {box_height:.6f}\"\n",
        "                #print(new_label)\n",
        "                new_labels.append(new_label)\n",
        "\n",
        "            output_file = os.path.join(output_folder, label_file)\n",
        "            with open(output_file, 'w') as f_out:\n",
        "                f_out.write(\"\\n\".join(new_labels))\n",
        "\n",
        "    print(f\"Converted labels saved to {output_folder}\")\n",
        "\n",
        "input_folder = '/content/DATASET_CUSTOMIZADO_TCC/train/labels'  # Folder with segmentation labels\n",
        "output_folder = '/content/Dataset_Converted/train/labels'  # Folder to save YOLO labels\n",
        "image_folder = '/content/DATASET_CUSTOMIZADO_TCC/train/images'  # Folder where corresponding images are stored\n",
        "\n",
        "convert_segmentation_to_yolo(input_folder, output_folder, image_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ALBLUMENTATIONS CHECK**\n",
        "\n",
        "Script created purely to understand how on-fly augmentations affect image"
      ],
      "metadata": {
        "id": "SeJANErdbuyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq1HiT-7KVos"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "\n",
        "#Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
        "\n",
        "image = cv2.imread('/content/3d-fdm-failures-6/train/images/a_jpg.rf.d71fc3017c62a4cc48cf3e0508ea82ee.jpg')\n",
        "image_height = image.shape[0]\n",
        "image_width = image.shape[1]\n",
        "\n",
        "albu_pipeline = A.Compose([\n",
        "    # A.Crop(x_min=0, y_min=0, x_max=image_width // 2, y_max=image_height // 2)\n",
        "    A.Blur(p=1, blur_limit=(3, 7)),\n",
        "    A.MedianBlur(p=1, blur_limit=(3, 7)),\n",
        "    A.ToGray(p=1, num_output_channels=3, method='weighted_average'),\n",
        "    A.CLAHE(p=1, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
        "])\n",
        "\n",
        "augmented_image = albu_pipeline(image=image)[\"image\"]\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "\n",
        "axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "axs[0].set_title(\"Original\")\n",
        "\n",
        "axs[1].imshow( cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "axs[1].set_title(\"Augmented\")\n",
        "\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DUPLICATES DETECTION**\n",
        "\n",
        "Script which compares naming of images to detect possible duplicates of images"
      ],
      "metadata": {
        "id": "Ua15R-_Eb-Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the part of the filename before %.rf.%\n",
        "def extract_base_name(filename):\n",
        "    return filename.split('.rf.')[0]\n",
        "\n",
        "# calculate the percentage similarity between two strings\n",
        "def calculate_similarity(name1, name2):\n",
        "    return SequenceMatcher(None, name1, name2).ratio() * 100\n",
        "\n",
        "def find_similar_files(valid_folder, test_folder, threshold=80, save_to_excel=False, output_file=\"similar_files.xlsx\"):\n",
        "    valid_files = [f for f in os.listdir(valid_folder) if os.path.isfile(os.path.join(valid_folder, f))]\n",
        "    test_files = [f for f in os.listdir(test_folder) if os.path.isfile(os.path.join(test_folder, f))]\n",
        "\n",
        "    similar_files = []  # list to store results\n",
        "\n",
        "    # compare files based on base names\n",
        "    for valid_file in valid_files:\n",
        "        valid_base = extract_base_name(valid_file)\n",
        "        for test_file in test_files:\n",
        "            test_base = extract_base_name(test_file)\n",
        "            similarity = calculate_similarity(valid_base, test_base)\n",
        "            if similarity >= threshold:\n",
        "                similar_files.append([valid_file, test_file, round(similarity, 2)])\n",
        "\n",
        "    df = pd.DataFrame(similar_files, columns=[\"Validation File\", \"Test File\", \"Similarity (%)\"])\n",
        "\n",
        "    if not df.empty:\n",
        "        print(f\"\\nFiles with similarity >= {threshold}% based on base names:\\n\")\n",
        "        print(df.to_string(index=False))\n",
        "        if save_to_excel:\n",
        "            df.to_excel(output_file, index=False)\n",
        "            print(f\"\\nResults saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"No files found with similarity >= {threshold}% based on base names.\")\n",
        "\n",
        "valid_folder = \"/content/3d-fdm-failures-6/valid/images\"\n",
        "test_folder = \"/content/3d-fdm-failures-6/train/images\"\n",
        "similarity_threshold = 100  # threshold for similarity\n",
        "find_similar_files(valid_folder, test_folder, similarity_threshold, save_to_excel=True)\n"
      ],
      "metadata": {
        "id": "kml1wofbKTV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPERIMENTS**\n",
        "\n",
        "This section contains script for executing experiments. Experiments are configured in .yaml files on Google Drive.\n",
        "\n",
        "Script iterates through all .yaml files, trains appropriate model and moves results to Google Drive for further analysis.\n",
        "\n",
        "**Note:** make sure to run cell with `!pip install`, since numpy ocasionally causes errors"
      ],
      "metadata": {
        "id": "rvHOgwhm4vEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy --no-cache-dir\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir ultralytics"
      ],
      "metadata": {
        "id": "3x-tPCbYKHhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load .yaml config file\n",
        "def load_yaml_config(yaml_path):\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# select yolov8 size for experiment\n",
        "def select_model_from_filename(filename):\n",
        "    return 'yolov8s.pt' if 'YOLO_S' in filename else 'yolov8n.pt'\n",
        "\n",
        "# initiate training with selected cfg\n",
        "def train_yolo_model(config_path, config):\n",
        "    model_path = select_model_from_filename(os.path.basename(config_path))\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    name = config.get('name', 'default_run')\n",
        "    project = config.get('project', 'default_project')\n",
        "    data_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "    print(f\"Starting Experiment: {name}\")\n",
        "    model.train(\n",
        "        data=data_path,\n",
        "        cfg=config_path,\n",
        "        project=project,\n",
        "        name=name,\n",
        "    )\n",
        "    return project, name\n",
        "\n",
        "# move result of experiment to google drive\n",
        "def move_run_output(project, name, dest_root):\n",
        "    src = os.path.join('/content', project, name)\n",
        "    dst = os.path.join(dest_root, name)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"Moved: {src} to {dst}\")\n",
        "    else:\n",
        "        print(f\"Output folder not found: {src}\")\n",
        "\n",
        "# main loop for experiments training\n",
        "def run_all_experiments(config_dir, final_output_dir):\n",
        "    for file in os.listdir(config_dir):\n",
        "        if file.endswith('.yaml'):\n",
        "            config_path = os.path.join(config_dir, file)\n",
        "            try:\n",
        "                config = load_yaml_config(config_path)\n",
        "                project, name = train_yolo_model(config_path, config)\n",
        "                move_run_output(project, name, final_output_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"Exception at {file}: {e}\")\n",
        "\n",
        "\n",
        "CONFIG_DIR = '/content/drive/MyDrive/Experiments_YAML_files'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/BP_Test'\n",
        "run_all_experiments(CONFIG_DIR, OUTPUT_DIR)\n"
      ],
      "metadata": {
        "id": "8b3NnXMoCKb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THESIS IMAGES MANIPULATIONS**\n",
        "\n",
        "Section with helped with merging images"
      ],
      "metadata": {
        "id": "heZcwLbEMDaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_keep_ratio(img, height):\n",
        "    scale = height / img.shape[0]\n",
        "    width = int(img.shape[1] * scale)\n",
        "    return cv2.resize(img, (width, height))\n",
        "\n",
        "def combine_graphs(img1_path, img2_path, output_path='combined.jpg', remove_legend_from='right', legend_coords=None, remove_pixels=400):\n",
        "\n",
        "    img1 = cv2.imread(img1_path)\n",
        "    img2 = cv2.imread(img2_path)\n",
        "\n",
        "    if img1 is None or img2 is None:\n",
        "        raise FileNotFoundError(\"One or both image paths are incorrect.\")\n",
        "\n",
        "    # remove legend\n",
        "    if remove_legend_from and legend_coords:\n",
        "        x1, y1, x2, y2 = legend_coords\n",
        "        if remove_legend_from.lower() == 'left':\n",
        "            img1[y1:y2, x1:x2] = 255\n",
        "        elif remove_legend_from.lower() == 'right':\n",
        "            img2[y1:y2, x1:x2] = 255\n",
        "\n",
        "    # resize to the same height\n",
        "    h1, w1 = img1.shape[:2]\n",
        "    h2, w2 = img2.shape[:2]\n",
        "    max_height = max(h1, h2)\n",
        "\n",
        "    img1_resized = resize_keep_ratio(img1, max_height)\n",
        "    img2_resized = resize_keep_ratio(img2, max_height)\n",
        "\n",
        "    # cut out extra space from right side of left image\n",
        "    img1_resized = img1_resized[:, :-remove_pixels]\n",
        "\n",
        "    combined = np.hstack((img1_resized, img2_resized))\n",
        "\n",
        "    # Save as JPEG\n",
        "    final_image = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)\n",
        "    pil_img = Image.fromarray(final_image)\n",
        "    pil_img.save(output_path, format='JPEG')\n",
        "\n",
        "    print(f\"image saved to {output_path}\")\n",
        "\n",
        "combine_graphs('/content/F1_Adamax_YOLO_S.jpg', '/content/PR_Adamax_YOLO_S.jpg', 'F1_Adamax_YOLO_S_PR_Adamax_YOLO_S.jpg', remove_legend_from='left', legend_coords=(1857, 115,2485, 795))\n"
      ],
      "metadata": {
        "id": "MY3TtBjFB7kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_combine_graphs(f1_dir, pr_dir, output_dir, legend_coords=None, remove_legend_from='right', remove_pixels=50):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    f1_files = [f for f in os.listdir(f1_dir) if f.startswith('F1_') and f.endswith('.jpg')]\n",
        "\n",
        "    for f1_file in f1_files:\n",
        "        base_name = f1_file.replace('F1_', '')\n",
        "        pr_file = f'PR_{base_name}'\n",
        "\n",
        "        f1_path = os.path.join(f1_dir, f1_file)\n",
        "        pr_path = os.path.join(pr_dir, pr_file)\n",
        "\n",
        "        if os.path.exists(pr_path):\n",
        "            output_filename = f'combined_{f1_file.replace(\".jpg\", \"\")}_{pr_file}'\n",
        "            output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "            try:\n",
        "                combine_graphs(f1_path, pr_path, output_path=output_path,\n",
        "                               remove_legend_from=remove_legend_from,\n",
        "                               legend_coords=legend_coords,\n",
        "                               remove_pixels=remove_pixels)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to combine {f1_file} and {pr_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"PR image not found for: {f1_file}\")\n",
        "\n",
        "\n",
        "batch_combine_graphs('/content/Experiment_Results_JPG/F1', '/content/Experiment_Results_JPG/PR', 'fixed', legend_coords=(1564, 80, 1875, 938), remove_legend_from='left', remove_pixels=300)\n"
      ],
      "metadata": {
        "id": "wgnYYQdMJqkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_embed_legend(image_path, legend_coords, scale_factor=1.5):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Failed to load image {image_path}\")\n",
        "        return\n",
        "\n",
        "    x1, y1, x2, y2 = legend_coords\n",
        "    legend = image[y1:y2, x1:x2]\n",
        "    legend_resized = cv2.resize(legend, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    h_new, w_new = legend_resized.shape[:2]\n",
        "    h_img, w_img = image.shape[:2]\n",
        "\n",
        "    new_canvas = np.ones((max(h_img, y1 + h_new), max(w_img, x1 + w_new), 3), dtype=np.uint8) * 255\n",
        "    new_canvas[:h_img, :w_img] = image\n",
        "    new_canvas[y1:y1 + h_new, x1:x1 + w_new] = legend_resized\n",
        "\n",
        "    output_path = image_path.replace('.jpg', '.jpg')\n",
        "    cv2.imwrite(output_path, new_canvas)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def batch_combine_graphs(f1_dir, pr_dir, output_dir, legend_coords=None, remove_legend_from='right', zoom_legend=False):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    f1_files = [f for f in os.listdir(f1_dir) if f.startswith('F1_') and f.endswith('.jpg')]\n",
        "\n",
        "    for f1_file in f1_files:\n",
        "        base_name = f1_file.replace('F1_', '')\n",
        "        pr_file = f'PR_{base_name}'\n",
        "\n",
        "        f1_path = os.path.join(f1_dir, f1_file)\n",
        "        pr_path = os.path.join(pr_dir, pr_file)\n",
        "\n",
        "        if os.path.exists(pr_path):\n",
        "            output_filename = f'{f1_file.replace(\".jpg\", \"\")}_{pr_file}'\n",
        "            output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "            try:\n",
        "                combine_graphs(f1_path, pr_path, output_path=output_path,\n",
        "                               remove_legend_from=remove_legend_from,\n",
        "                               legend_coords=legend_coords)\n",
        "\n",
        "                if zoom_legend and legend_coords:\n",
        "                    resize_and_embed_legend(output_path, legend_coords)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to combine {f1_file} and {pr_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"PR image not found for: {f1_file}\")\n",
        "\n",
        "\n",
        "batch_combine_graphs(\n",
        "    f1_dir='/content/Experiment_Results_JPG/F1',\n",
        "    pr_dir='/content/Experiment_Results_JPG/PR',\n",
        "    output_dir='/content/combined',\n",
        "    legend_coords=(4125, 100, 4687, 830),\n",
        "    remove_legend_from='left',\n",
        "    zoom_legend=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ivgq9LleujN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_embed_legend('/content/F1_Baseline_YOLO_S_PR_Baseline_YOLO_S.jpg', (3965, 105, 4600, 775))"
      ],
      "metadata": {
        "id": "0US03uGiacxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}